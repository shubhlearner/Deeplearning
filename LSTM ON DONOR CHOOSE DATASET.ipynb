{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1\n",
    "\n",
    "Build and Train deep neural network as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Input_seq_total_text_data__ --- You have to give Total text data columns. After this use the Embedding layer to get word vectors. Use given predefined glove word vectors, don't train any word vectors. After this use LSTM and get the LSTM output and Flatten that output. \n",
    "- __Input_school_state__ --- Give 'school_state' column as input to embedding layer and Train the Keras Embedding layer. \n",
    "- __Project_grade_category__  --- Give 'project_grade_category' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_categories__ --- Give 'input_clean_categories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_clean_subcategories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_teacher_prefix' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_remaining_teacher_number_of_previously_posted_projects._resource_summary_contains_numerical_digits._price._quantity__ ---concatenate remaining columns and add a Dense layer after that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For LSTM, you can choose your sequence padding methods on your own or you can train your LSTM without padding, there is no restriction on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of embedding layer for a categorical columns. In below code all are dummy values, we gave only for referance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
    "input_layer = Input(shape=(n,))\n",
    "embedding = Embedding(no_1, no_2, input_length=n)(input_layer)\n",
    "flatten = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "### 2. Please go through this link https://keras.io/getting-started/functional-api-guide/ and check the 'Multi-input and multi-output models' then you will get to know how to give multiple inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Input, Embedding, LSTM, Dropout, BatchNormalization, Dense, concatenate, Flatten, Conv1D, MaxPool1D, LeakyReLU, ELU, SpatialDropout1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  725.05  \n",
       "1  imagine 8 9 years old you third grade classroo...  213.03  \n",
       "2  having class 24 students comes diverse learner...  329.00  \n",
       "3  i recently read article giving students choice...  481.04  \n",
       "4  my students crave challenge eat obstacles brea...   17.74  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data = pd.read_csv('preprocessed_data.csv')\n",
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = project_data.sample(n=100000, random_state=42)\n",
    "# We split our dataset into train,cross-validation and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = project_data['project_is_approved']\n",
    "project_data.drop(['project_is_approved'], axis = 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(project_data, Y,stratify=Y,test_size=0.25,random_state=123)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train,stratify=y_train,test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (56250, 9)\n",
      "cv data shape: (18750, 9)\n",
      "Test data shape: (25000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape:\", x_train.shape)\n",
    "print(\"cv data shape:\", x_cv.shape)\n",
    "print(\"Test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(x_train[\"essay\"])\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length 43794\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary length\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train.essay)\n",
    "encoded_docs_train = tokenizer.texts_to_sequences(x_train[\"essay\"])\n",
    "encoded_docs_cv = tokenizer.texts_to_sequences(x_cv[\"essay\"])\n",
    "encoded_docs_test = tokenizer.texts_to_sequences(x_test[\"essay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43831"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 500\n",
    "\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_length, padding='post')\n",
    "padded_docs_cv = pad_sequences(encoded_docs_cv, maxlen=max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train text shape: (56250, 500)\n",
      "Encoded cv text shape: (18750, 500)\n",
      "Encoded test text shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded train text shape:\", padded_docs_train.shape)\n",
    "print(\"Encoded cv text shape:\", padded_docs_cv.shape)\n",
    "print(\"Encoded test text shape:\", padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler().fit(padded_docs_train)\n",
    "padded_docs_train_stan = ss.transform(padded_docs_train)\n",
    "padded_docs_cv_stan = ss.transform(padded_docs_cv)\n",
    "padded_docs_test_stan = ss.transform(padded_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape (43831, 300)\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding Matrix Shape\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sizes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"school_state\"])\n",
    "\n",
    "train_state = vect.transform(x_train[\"school_state\"])\n",
    "cv_state = vect.transform(x_cv[\"school_state\"])\n",
    "test_state = vect.transform(x_test[\"school_state\"])\n",
    "cat_sizes['school_state'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"project_grade_category\"])\n",
    "\n",
    "train_project_grade_category = vect.transform(x_train[\"project_grade_category\"])\n",
    "cv_project_grade_category = vect.transform(x_cv[\"project_grade_category\"])\n",
    "test_project_grade_category = vect.transform(x_test[\"project_grade_category\"])\n",
    "cat_sizes['project_grade_category'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"clean_categories\"])\n",
    "\n",
    "train_clean_categories = vect.transform(x_train[\"clean_categories\"])\n",
    "cv_clean_categories = vect.transform(x_cv[\"clean_categories\"])\n",
    "test_clean_categories = vect.transform(x_test[\"clean_categories\"])\n",
    "cat_sizes['clean_categories'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"clean_subcategories\"])\n",
    "\n",
    "train_clean_subcategories = vect.transform(x_train[\"clean_subcategories\"])\n",
    "cv_clean_subcategories = vect.transform(x_cv[\"clean_subcategories\"])\n",
    "test_clean_subcategories = vect.transform(x_test[\"clean_subcategories\"])\n",
    "cat_sizes['clean_subcategories'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"teacher_prefix\"])\n",
    "\n",
    "train_teacher_prefix = vect.transform(x_train[\"teacher_prefix\"])\n",
    "cv_teacher_prefix = vect.transform(x_cv[\"teacher_prefix\"])\n",
    "test_teacher_prefix = vect.transform(x_test[\"teacher_prefix\"])\n",
    "cat_sizes['teacher_prefix'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@davidheffernan_99410/an-introduction-to-using-categorical-embeddings-ee686ed7e7f9\n",
    "cat_vars = [\"school_state\",\"project_grade_category\", \"clean_categories\", \"clean_subcategories\", \"teacher_prefix\"]\n",
    "cat_embsizes = {}\n",
    "for cat in cat_vars:\n",
    "    cat_embsizes[cat] = min(50, cat_sizes[cat]//2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_input_train = np.concatenate((x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_train['price'].values.reshape(-1,1)), axis=1)\n",
    "rem_input_cv = np.concatenate((x_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_cv['price'].values.reshape(-1,1)), axis=1)\n",
    "rem_input_test = np.concatenate((x_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_test['price'].values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(rem_input_train)\n",
    "rem_input_train_stan = ss.transform(rem_input_train)\n",
    "rem_input_cv_stan = ss.transform(rem_input_cv)\n",
    "rem_input_test_stan = ss.transform(rem_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_binary_train = to_categorical(y_train)\n",
    "y_binary_cv = to_categorical(y_cv)\n",
    "y_binary_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.layers import LeakyReLU\n",
    "inputs = []\n",
    "concat = []\n",
    "\n",
    "text_input = Input(shape=(max_length,), name = \"text_input\")\n",
    "inputs.append(text_input)\n",
    "e1 = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length,trainable=False)(text_input)\n",
    "\n",
    "l1= LSTM(256, kernel_initializer='he_normal', recurrent_dropout=0.5, kernel_regularizer=l2(0.001), return_sequences=True, activation='relu')(e1)\n",
    "f1= Flatten()(l1)\n",
    "concat.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape\n",
    "\n",
    "for cat in cat_vars:\n",
    "    x = Input((cat_sizes[cat],), name=cat)\n",
    "    inputs.append(x)\n",
    "    x = Embedding(cat_sizes[cat]+1, cat_embsizes[cat], input_length=cat_sizes[cat])(x)\n",
    "    x = Flatten()(x)\n",
    "    concat.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_input_layer =  Input((2,), name=\"rem_input_layer\")\n",
    "inputs.append(rem_input_layer)\n",
    "rem_input_dense = Dense(128, activation='relu',kernel_initializer='he_normal')(rem_input_layer)\n",
    "concat.append(rem_input_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "x = Concatenate()(concat)\n",
    "x= Dense(256, activation='relu', input_shape=(5,))(x)\n",
    "x= Dropout(0.25)(x)\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(64, activation='relu')(x)\n",
    "output=Dense(2, activation='softmax')(x)\n",
    "model_l = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 500, 300)     13149300    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "school_state (InputLayer)       (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500, 256)     570368      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 51, 26)       1352        school_state[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 4, 3)         15          project_grade_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 9, 5)         50          clean_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 30, 16)       496         clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 5, 3)         18          teacher_prefix[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "rem_input_layer (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128000)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1326)         0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 12)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 45)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 480)          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 15)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          384         rem_input_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 130006)       0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          33281792    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            130         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,045,057\n",
      "Trainable params: 33,895,757\n",
      "Non-trainable params: 13,149,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, sample_weight=None).astype('float32'),\n",
    "                    [y_true, y_pred],\n",
    "                    'float32',\n",
    "                    stateful=True,\n",
    "                    name='sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model_l.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from time import time\n",
    "\n",
    "mcp_save = ModelCheckpoint('../working/mdl_wts.hdf5', save_best_only=True, monitor='accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='auto')\n",
    "tb = TensorBoard(log_dir='../working/logs'.format(time()))\n",
    "\n",
    "callbacks_lst = [mcp_save, reduce_lr_loss, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56250 samples, validate on 18750 samples\n",
      "Epoch 1/10\n",
      "56250/56250 [==============================] - 103s 2ms/step - loss: 1.2815 - auc: 0.8664 - val_loss: 0.6305 - val_auc: 0.8806\n",
      "Epoch 2/10\n",
      "56250/56250 [==============================] - 99s 2ms/step - loss: 0.5003 - auc: 0.8780 - val_loss: 0.4444 - val_auc: 0.8818\n",
      "Epoch 3/10\n",
      "56250/56250 [==============================] - 99s 2ms/step - loss: 0.4220 - auc: 0.8814 - val_loss: 0.4230 - val_auc: 0.8821\n",
      "Epoch 4/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.4132 - auc: 0.8844 - val_loss: 0.4218 - val_auc: 0.8815\n",
      "Epoch 5/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.4084 - auc: 0.8887 - val_loss: 0.4191 - val_auc: 0.8805\n",
      "Epoch 6/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.4050 - auc: 0.8926 - val_loss: 0.4183 - val_auc: 0.8796\n",
      "Epoch 7/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.3988 - auc: 0.8980 - val_loss: 0.4249 - val_auc: 0.8769\n",
      "Epoch 8/10\n",
      "56250/56250 [==============================] - 99s 2ms/step - loss: 0.3897 - auc: 0.9053 - val_loss: 0.4313 - val_auc: 0.8752\n",
      "Epoch 9/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.3724 - auc: 0.9158 - val_loss: 0.4486 - val_auc: 0.8737\n",
      "Epoch 10/10\n",
      "56250/56250 [==============================] - 100s 2ms/step - loss: 0.3474 - auc: 0.9286 - val_loss: 0.4822 - val_auc: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f969d827240>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l.fit(x={'text_input': padded_docs_train_stan.astype(np.float32), 'school_state': train_state, 'project_grade_category': train_project_grade_category,\n",
    "                        'clean_categories': train_clean_categories,'clean_subcategories': train_clean_subcategories, \n",
    "                        'teacher_prefix': train_teacher_prefix, 'rem_input_layer':rem_input_train_stan.astype(np.float32)}, \n",
    "                       y=y_binary_train, epochs=10, batch_size=batch_size,verbose=1, \n",
    "                       validation_data=({'text_input': padded_docs_cv_stan.astype(np.float32), 'school_state': cv_state, 'project_grade_category': cv_project_grade_category,\n",
    "                        'clean_categories': cv_clean_categories,'clean_subcategories': cv_clean_subcategories, \n",
    "                        'teacher_prefix': cv_teacher_prefix, 'rem_input_layer':rem_input_cv_stan.astype(np.float32)}, y_binary_cv),\n",
    "                      callbacks=callbacks_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 228s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4701386535263061, 0.8694175]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l.evaluate({'text_input': padded_docs_test_stan.astype(np.float32), 'school_state': test_state, 'project_grade_category': test_project_grade_category,\n",
    "                        'clean_categories': test_clean_categories,'clean_subcategories': test_clean_subcategories, \n",
    "                        'teacher_prefix': test_teacher_prefix, 'rem_input_layer':rem_input_test_stan.astype(np.float32)}, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=../working/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': '../working/logs/' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-29e23e59-804e-49ce-a2e2-9ca37117af4b');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-29e23e59-804e-49ce-a2e2-9ca37117af4b\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=../working/logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC  \n",
    "<img src='Screenshot (240).png'>  \n",
    "* Loss  \n",
    "<img src='Screenshot (241).png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "1. Train the TF-IDF on the Train data feature 'essay' <br>\n",
    "2. Get the idf value for each word we have in the train data. <br>\n",
    "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)<br>\n",
    "4. Train the LSTM after removing the Low and High idf value words. (In model-1 Train on total data but in Model-2 train on data after removing some words based on IDF values)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,max_features=10000)\n",
    "word_vector = vectorizer.fit(x_train.essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f922c8d8390>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_values = vectorizer.idf_\n",
    "sns.boxplot(y=\"idf\", data=pd.DataFrame(idf_values, columns= [\"idf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 1.0078349186743243\n",
      "25 percentile value is 6.264255830514929\n",
      "50 percentile value is 7.543129943013983\n",
      "75 percentile value is 8.326661185042198\n",
      "100 percentile value is  9.539683824888051\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,25):\n",
    "    var = idf_values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF values: 10000 ,Total featuers: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"IDF values:\", len(idf_values), \",Total featuers:\", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_words = {}\n",
    "feature_list = vectorizer.get_feature_names()\n",
    "for i in range(len(idf_values)):\n",
    "    if idf_values[i] >= 6.26 and idf_values[i] <= 8.32:\n",
    "        imp_words[feature_list[i]] = idf_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "x = imp_words.values()\n",
    "def remove_words(sentences):\n",
    "    imp_essay = []\n",
    "    for sent in tqdm_notebook(sentences):\n",
    "        lst = []\n",
    "        for e in sent.lower().split():\n",
    "            lst.append(e)\n",
    "        imp_essay.append(' '.join(lst))\n",
    "        lst.clear()\n",
    "    return imp_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0d950b0d984802aa3ff780aa8606d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6cbbb1feb8424e8f82b71d8c542a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18750), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae029c3944fe4864a2ddffe1cae46846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_imp = remove_words(x_train.essay.tolist())\n",
    "x_cv_imp = remove_words(x_cv.essay.tolist())\n",
    "x_test_imp = remove_words(x_test.essay.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train_imp)\n",
    "encoded_docs_train = tokenizer.texts_to_sequences(x_train_imp)\n",
    "encoded_docs_cv = tokenizer.texts_to_sequences(x_cv_imp)\n",
    "encoded_docs_test = tokenizer.texts_to_sequences(x_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43831"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 500\n",
    "\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_length, padding='post')\n",
    "padded_docs_cv = pad_sequences(encoded_docs_cv, maxlen=max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train text shape: (56250, 500)\n",
      "Encoded cv text shape: (18750, 500)\n",
      "Encoded test text shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded train text shape:\", padded_docs_train.shape)\n",
    "print(\"Encoded cv text shape:\", padded_docs_cv.shape)\n",
    "print(\"Encoded test text shape:\", padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape (43831, 300)\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding Matrix Shape\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sizes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"school_state\"])\n",
    "\n",
    "train_state = vect.transform(x_train[\"school_state\"])\n",
    "cv_state = vect.transform(x_cv[\"school_state\"])\n",
    "test_state = vect.transform(x_test[\"school_state\"])\n",
    "cat_sizes['school_state'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"project_grade_category\"])\n",
    "\n",
    "train_project_grade_category = vect.transform(x_train[\"project_grade_category\"])\n",
    "cv_project_grade_category = vect.transform(x_cv[\"project_grade_category\"])\n",
    "test_project_grade_category = vect.transform(x_test[\"project_grade_category\"])\n",
    "cat_sizes['project_grade_category'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"clean_categories\"])\n",
    "\n",
    "train_clean_categories = vect.transform(x_train[\"clean_categories\"])\n",
    "cv_clean_categories = vect.transform(x_cv[\"clean_categories\"])\n",
    "test_clean_categories = vect.transform(x_test[\"clean_categories\"])\n",
    "cat_sizes['clean_categories'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"clean_subcategories\"])\n",
    "\n",
    "train_clean_subcategories = vect.transform(x_train[\"clean_subcategories\"])\n",
    "cv_clean_subcategories = vect.transform(x_cv[\"clean_subcategories\"])\n",
    "test_clean_subcategories = vect.transform(x_test[\"clean_subcategories\"])\n",
    "cat_sizes['clean_subcategories'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit(x_train[\"teacher_prefix\"])\n",
    "\n",
    "train_teacher_prefix = vect.transform(x_train[\"teacher_prefix\"])\n",
    "cv_teacher_prefix = vect.transform(x_cv[\"teacher_prefix\"])\n",
    "test_teacher_prefix = vect.transform(x_test[\"teacher_prefix\"])\n",
    "cat_sizes['teacher_prefix'] = len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@davidheffernan_99410/an-introduction-to-using-categorical-embeddings-ee686ed7e7f9\n",
    "cat_vars = [\"school_state\",\"project_grade_category\", \"clean_categories\", \"clean_subcategories\", \"teacher_prefix\"]\n",
    "cat_embsizes = {}\n",
    "for cat in cat_vars:\n",
    "    cat_embsizes[cat] = min(50, cat_sizes[cat]//2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_input_train = np.concatenate((x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_train['price'].values.reshape(-1,1)), axis=1)\n",
    "rem_input_cv = np.concatenate((x_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_cv['price'].values.reshape(-1,1)), axis=1)\n",
    "rem_input_test = np.concatenate((x_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1), x_test['price'].values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_binary_train = to_categorical(y_train)\n",
    "y_binary_cv = to_categorical(y_cv)\n",
    "y_binary_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.layers import LeakyReLU\n",
    "inputs = []\n",
    "concat = []\n",
    "\n",
    "text_input = Input(shape=(max_length,), name = \"text_input\")\n",
    "inputs.append(text_input)\n",
    "e1 = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length,trainable=False)(text_input)\n",
    "\n",
    "l1= LSTM(256, kernel_initializer='he_normal', recurrent_dropout=0.5, kernel_regularizer=l2(0.001), return_sequences=True, activation='relu')(e1)\n",
    "f1= Flatten()(l1)\n",
    "concat.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape\n",
    "\n",
    "for cat in cat_vars:\n",
    "    x = Input((cat_sizes[cat],), name=cat)\n",
    "    inputs.append(x)\n",
    "    x = Embedding(cat_sizes[cat]+1, cat_embsizes[cat], input_length=cat_sizes[cat])(x)\n",
    "    x = Flatten()(x)\n",
    "    concat.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_input_layer =  Input((2,), name=\"rem_input_layer\")\n",
    "inputs.append(rem_input_layer)\n",
    "rem_input_dense = Dense(128, activation='relu',kernel_initializer='he_normal')(rem_input_layer)\n",
    "concat.append(rem_input_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "x = Concatenate()(concat)\n",
    "x= Dense(256, activation='relu', input_shape=(5,))(x)\n",
    "x= Dropout(0.25)(x)\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(64, activation='relu')(x)\n",
    "output=Dense(2, activation='softmax')(x)\n",
    "model_l = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 500, 300)     13149300    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "school_state (InputLayer)       (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 500, 256)     570368      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 51, 26)       1352        school_state[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 4, 3)         15          project_grade_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 9, 5)         50          clean_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 30, 16)       496         clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 5, 3)         18          teacher_prefix[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "rem_input_layer (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 128000)       0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1326)         0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 12)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 45)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 480)          0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 15)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          384         rem_input_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 130006)       0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          33281792    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            130         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,045,057\n",
      "Trainable params: 33,895,757\n",
      "Non-trainable params: 13,149,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, sample_weight=None).astype('float32'),\n",
    "                    [y_true, y_pred],\n",
    "                    'float32',\n",
    "                    stateful=True,\n",
    "                    name='sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model_l.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from time import time\n",
    "\n",
    "mcp_save = ModelCheckpoint('../working/mdl_wts.hdf5', save_best_only=True, monitor='accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='auto')\n",
    "tb = TensorBoard(log_dir='../working/logs'.format(time()))\n",
    "\n",
    "callbacks_lst = [mcp_save, reduce_lr_loss, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56250 samples, validate on 18750 samples\n",
      "Epoch 1/10\n",
      "56250/56250 [==============================] - 103s 2ms/step - loss: 1.4036 - auc: 0.8449 - val_loss: 0.6199 - val_auc: 0.8488\n",
      "Epoch 2/10\n",
      "56250/56250 [==============================] - 101s 2ms/step - loss: 0.4983 - auc: 0.8475 - val_loss: 0.4388 - val_auc: 0.8488\n",
      "Epoch 3/10\n",
      "56250/56250 [==============================] - 103s 2ms/step - loss: 0.4318 - auc: 0.8481 - val_loss: 0.4258 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "56250/56250 [==============================] - 102s 2ms/step - loss: 0.4266 - auc: 0.8496 - val_loss: 0.4250 - val_auc: 0.8488\n",
      "Epoch 5/10\n",
      "56250/56250 [==============================] - 101s 2ms/step - loss: 0.4267 - auc: 0.8479 - val_loss: 0.4249 - val_auc: 0.8488\n",
      "Epoch 6/10\n",
      "56250/56250 [==============================] - 102s 2ms/step - loss: 0.4262 - auc: 0.8490 - val_loss: 0.4250 - val_auc: 0.8488\n",
      "Epoch 7/10\n",
      "56250/56250 [==============================] - 102s 2ms/step - loss: 0.4261 - auc: 0.8482 - val_loss: 0.4248 - val_auc: 0.8488\n",
      "Epoch 8/10\n",
      "56250/56250 [==============================] - 101s 2ms/step - loss: 0.4255 - auc: 0.8510 - val_loss: 0.4249 - val_auc: 0.8488\n",
      "Epoch 9/10\n",
      "56250/56250 [==============================] - 103s 2ms/step - loss: 0.4258 - auc: 0.8483 - val_loss: 0.4249 - val_auc: 0.8488\n",
      "Epoch 10/10\n",
      "56250/56250 [==============================] - 102s 2ms/step - loss: 0.4257 - auc: 0.8484 - val_loss: 0.4251 - val_auc: 0.8488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96bb156ef0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l.fit(x={'text_input': padded_docs_train, 'school_state': train_state, 'project_grade_category': train_project_grade_category,\n",
    "                        'clean_categories': train_clean_categories,'clean_subcategories': train_clean_subcategories, \n",
    "                        'teacher_prefix': train_teacher_prefix, 'rem_input_layer':rem_input_train}, \n",
    "                       y=y_binary_train, epochs=10, batch_size=batch_size,verbose=1, \n",
    "                       validation_data=({'text_input': padded_docs_cv, 'school_state': cv_state, 'project_grade_category': cv_project_grade_category,\n",
    "                        'clean_categories': cv_clean_categories,'clean_subcategories': cv_clean_subcategories, \n",
    "                        'teacher_prefix': cv_teacher_prefix, 'rem_input_layer':rem_input_cv}, y_binary_cv),\n",
    "                      callbacks=callbacks_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 232s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42508111223220824, 0.8488]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l.evaluate({'text_input': padded_docs_test, 'school_state': test_state, 'project_grade_category': test_project_grade_category,\n",
    "                        'clean_categories': test_clean_categories,'clean_subcategories': test_clean_subcategories, \n",
    "                        'teacher_prefix': test_teacher_prefix, 'rem_input_layer':rem_input_test}, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': '../working/logs/' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-bd6d9a51-d78a-4ba1-8da0-c8dc99a71479');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-bd6d9a51-d78a-4ba1-8da0-c8dc99a71479\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=../working/logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC  \n",
    "<img src='Screenshot (242).png'>  \n",
    "* Loss  \n",
    "<img src='Screenshot (243).png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- __input_seq_total_text_data__: <br>\n",
    "<pre>\n",
    "    . Use text column('essay'), and use the Embedding layer to get word vectors. <br>\n",
    "    . Use given predefined glove word vectors, don't train any word vectors. <br>\n",
    "    . Use LSTM that is given above, get the LSTM output and Flatten that output. <br>\n",
    "    . You are free to preprocess the input text as you needed. <br>\n",
    "</pre>\n",
    "- __Other_than_text_data__:<br>\n",
    "<pre>\n",
    "    . Convert all your Categorical values to onehot coded and then concatenate all these onehot vectors <br>\n",
    "    . Neumerical values and use <a href='https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-1d-convolutions'>CNN1D</a> as shown in above figure. <br>\n",
    "    . You are free to choose all CNN parameters like kernel sizes, stride.<br>\n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(x_train['price'].values.reshape(-1,1))\n",
    "\n",
    "x_train_price_norm = normalizer.transform(x_train['price'].values.reshape(-1,1))\n",
    "x_cv_price_norm = normalizer.transform(x_cv['price'].values.reshape(-1,1))\n",
    "x_test_price_norm = normalizer.transform(x_test['price'].values.reshape(-1,1))\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "\n",
    "x_train_tpp_norm = normalizer.transform(x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "x_cv_tpp_norm = normalizer.transform(x_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "x_test_tpp_norm = normalizer.transform(x_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(56250, 101) (56250,)\n",
      "(18750, 101) (18750,)\n",
      "(25000, 101) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "x_tr_rem = hstack((train_state, train_teacher_prefix, train_project_grade_category, train_clean_subcategories, train_clean_categories, x_train_price_norm, x_train_tpp_norm)).todense()\n",
    "x_cv_rem = hstack((cv_state, cv_teacher_prefix, cv_project_grade_category, cv_clean_subcategories, cv_clean_categories, x_cv_price_norm, x_cv_tpp_norm)).todense()\n",
    "x_te_rem = hstack((test_state, test_teacher_prefix, test_project_grade_category, test_clean_subcategories,test_clean_categories, x_test_price_norm, x_test_tpp_norm)).todense()\n",
    "\n",
    "print(\"Final Data matrix\")\n",
    "print(x_tr_rem.shape, y_train.shape)\n",
    "print(x_cv_rem.shape, y_cv.shape)\n",
    "print(x_te_rem.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train.essay)\n",
    "encoded_docs_train = tokenizer.texts_to_sequences(x_train[\"essay\"])\n",
    "encoded_docs_cv = tokenizer.texts_to_sequences(x_cv[\"essay\"])\n",
    "encoded_docs_test = tokenizer.texts_to_sequences(x_test[\"essay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43831"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 500\n",
    "\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_length, padding='post')\n",
    "padded_docs_cv = pad_sequences(encoded_docs_cv, maxlen=max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train text shape: (56250, 500)\n",
      "Encoded cv text shape: (18750, 500)\n",
      "Encoded test text shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded train text shape:\", padded_docs_train.shape)\n",
    "print(\"Encoded cv text shape:\", padded_docs_cv.shape)\n",
    "print(\"Encoded test text shape:\", padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape (43831, 300)\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding Matrix Shape\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rem (InputLayer)                (None, 101, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 500, 300)     13149300    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 99, 128)      512         rem[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 500, 128)     219648      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 64)       24640       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64000)        0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 6208)         0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 70208)        0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          17973504    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          32896       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            130         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,408,886\n",
      "Trainable params: 31,408,886\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = Input(shape=(500,), name = \"text_input\")\n",
    "e1 = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=500)(text_input)\n",
    "l1= LSTM(128,activation = \"relu\",dropout=0.5,kernel_regularizer=l2(0.001),kernel_initializer='glorot_normal',return_sequences=True,input_shape=(150,300))(e1)\n",
    "f1= Flatten()(l1)\n",
    "\n",
    "rem = Input(shape=(x_tr_rem.shape[1],1), name=\"rem\")\n",
    "rem_conv1 = Conv1D(128, 3, activation='relu', kernel_initializer='glorot_normal')(rem)\n",
    "rem_conv2 =Conv1D(64, 3, activation='relu',kernel_initializer='glorot_normal' )(rem_conv1)\n",
    "f2= Flatten()(rem_conv2)\n",
    "x = keras.layers.concatenate([f1,f2])\n",
    "x= Dense(256, activation='sigmoid')(x)\n",
    "x= Dropout(0.25)(x)\n",
    "x= Dense(128, kernel_regularizer=l2(0.001),kernel_initializer='glorot_normal')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(64,kernel_regularizer=l2(0.001),kernel_initializer='glorot_normal')(x)\n",
    "output=Dense(2, activation='softmax')(x)\n",
    "model_3 = Model(inputs=[text_input,rem], outputs=output)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, sample_weight=None).astype('float32'),\n",
    "                    [y_true, y_pred],\n",
    "                    'float32',\n",
    "                    stateful=True,\n",
    "                    name='sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from time import time\n",
    "\n",
    "mcp_save = ModelCheckpoint('../working/mdl_wts.hdf5', save_best_only=True, monitor='accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='auto')\n",
    "tb = TensorBoard(log_dir='../working/logs'.format(time()))\n",
    "\n",
    "callbacks_lst = [mcp_save, reduce_lr_loss, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_rem_reshape = np.array(x_tr_rem).reshape(56250,101,1)\n",
    "x_cv_rem_reshape = np.array(x_cv_rem).reshape(18750, 101,1)\n",
    "x_test_rem_reshape = np.array(x_te_rem).reshape(25000, 101,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56250 samples, validate on 18750 samples\n",
      "Epoch 1/10\n",
      "56250/56250 [==============================] - 112s 2ms/step - loss: 1.1782 - auc: 0.8426 - val_loss: 0.6652 - val_auc: 0.9002\n",
      "Epoch 2/10\n",
      "56250/56250 [==============================] - 107s 2ms/step - loss: 0.6237 - auc: 0.8991 - val_loss: 0.5941 - val_auc: 0.9083\n",
      "Epoch 3/10\n",
      "56250/56250 [==============================] - 108s 2ms/step - loss: 0.5762 - auc: 0.9087 - val_loss: 0.5610 - val_auc: 0.9103\n",
      "Epoch 4/10\n",
      "56250/56250 [==============================] - 107s 2ms/step - loss: 0.5392 - auc: 0.9138 - val_loss: 0.5356 - val_auc: 0.9103\n",
      "Epoch 5/10\n",
      "56250/56250 [==============================] - 108s 2ms/step - loss: 0.5100 - auc: 0.9173 - val_loss: 0.5161 - val_auc: 0.9099\n",
      "Epoch 6/10\n",
      "56250/56250 [==============================] - 110s 2ms/step - loss: 0.4825 - auc: 0.9210 - val_loss: 0.5011 - val_auc: 0.9088\n",
      "Epoch 7/10\n",
      "56250/56250 [==============================] - 107s 2ms/step - loss: 0.4560 - auc: 0.9256 - val_loss: 0.4855 - val_auc: 0.9088\n",
      "Epoch 8/10\n",
      "56250/56250 [==============================] - 106s 2ms/step - loss: nan - auc: 0.8950 - val_loss: nan - val_auc: 0.8644\n",
      "Epoch 9/10\n",
      "56250/56250 [==============================] - 107s 2ms/step - loss: nan - auc: 0.8624 - val_loss: nan - val_auc: 0.8672\n",
      "Epoch 10/10\n",
      "56250/56250 [==============================] - 107s 2ms/step - loss: nan - auc: 0.8657 - val_loss: nan - val_auc: 0.8677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96ccb05710>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit({'text_input': padded_docs_train, 'rem':x_tr_rem_reshape}, y_binary_train, epochs=10, batch_size=batch_size,\n",
    "             verbose=1, validation_data=({'text_input': padded_docs_cv, 'rem': x_cv_rem_reshape},y_binary_cv),\n",
    "             callbacks=callbacks_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 245s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.86573375]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate({'text_input': padded_docs_test, 'rem': x_test_rem_reshape}, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': '../working/logs/' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-33116356-290f-46fd-9738-06d8bfd267a5');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-33116356-290f-46fd-9738-06d8bfd267a5\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=../working/logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|  model  | test_auc |\n",
      "+---------+----------+\n",
      "| model_1 |  0.8694  |\n",
      "| model_2 |  0.8488  |\n",
      "| model_3 |  0.8657  |\n",
      "+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "pt=PrettyTable()\n",
    "pt.field_names=[\"model\",\"test_auc\"]\n",
    "pt.add_row([\"model_1\", 0.8694])\n",
    "pt.add_row([\"model_2\", 0.8488])\n",
    "pt.add_row([\"model_3\", 0.8657])\n",
    "\n",
    "print(pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
